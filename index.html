<!DOCTYPE html>
<html lang="en" class="light">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>Universal AI - Hands-Free Voice & Vision</title>
    
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">

    <style>
        body { height: 100dvh; overflow: hidden; font-family: system-ui, -apple-system, sans-serif; }
        #chat-container { scroll-behavior: smooth; }
        .voice-bar { width: 5px; background: #3b82f6; border-radius: 5px; animation: wave 1s infinite; }
        @keyframes wave { 0%, 100% { height: 10px; } 50% { height: 25px; } }
        .active-mic { color: #ef4444 !important; animation: pulse 1.5s infinite; }
        @keyframes pulse { 0% { opacity: 1; } 50% { opacity: 0.5; } 100% { opacity: 1; } }
    </style>
</head>
<body class="bg-slate-50 text-slate-800 dark:bg-slate-900 dark:text-slate-100 transition-colors">

    <div id="app" class="flex h-full w-full overflow-hidden">
        
        <aside id="sidebar" class="fixed inset-y-0 left-0 z-40 w-[280px] bg-white dark:bg-slate-800 transform -translate-x-full lg:translate-x-0 lg:static transition-transform flex flex-col border-r dark:border-slate-700">
            <div class="p-4">
                <button onclick="createNewChat()" class="w-full flex items-center justify-center gap-2 bg-blue-600 text-white px-4 py-3 rounded-xl shadow-lg hover:bg-blue-700 transition-all font-bold">
                    <i class="fa-solid fa-plus"></i> New Conversation
                </button>
            </div>
            <div id="chat-list" class="flex-1 overflow-y-auto px-2 space-y-1"></div>
            <div class="p-4 border-t dark:border-slate-700 space-y-3">
                <div class="flex items-center justify-between text-xs font-bold uppercase text-slate-400">
                    <span>Hands-Free Mode</span>
                    <input type="checkbox" id="hands-free-toggle" onchange="toggleHandsFree()" class="w-4 h-4">
                </div>
                <button onclick="toggleSettings()" class="w-full text-left text-sm flex items-center gap-2"><i class="fa-solid fa-gear"></i> Settings</button>
            </div>
        </aside>

        <main class="flex-1 flex flex-col h-full bg-white dark:bg-slate-900 relative">
            <header class="h-14 flex items-center justify-between px-4 border-b dark:border-slate-800">
                <button onclick="toggleSidebar()" class="lg:hidden p-2 text-xl"><i class="fa-solid fa-bars"></i></button>
                <div id="status-tag" class="text-[10px] uppercase font-black bg-slate-100 dark:bg-slate-800 px-3 py-1 rounded-full text-slate-500">Standby</div>
                <button onclick="stopSpeaking()" id="stop-voice-btn" class="hidden text-xs bg-red-500 text-white px-3 py-1 rounded-full font-bold">STOP VOICE</button>
            </header>

            <div id="chat-container" class="flex-1 overflow-y-auto p-4 md:p-8 space-y-6"></div>

            <div class="p-4 max-w-4xl mx-auto w-full">
                <div id="img-preview-box" class="hidden flex p-2 gap-2 mb-2 bg-slate-100 dark:bg-slate-800 rounded-xl w-fit relative border shadow-sm">
                    <img id="preview-img" src="" class="h-20 w-20 object-cover rounded-lg">
                    <button onclick="clearImage()" class="absolute -top-2 -right-2 bg-red-500 text-white rounded-full w-6 h-6 flex items-center justify-center"><i class="fa-solid fa-xmark text-xs"></i></button>
                </div>

                <div id="voice-indicator" class="hidden flex justify-center gap-1 mb-3">
                    <div class="voice-bar" style="animation-delay: 0.1s"></div>
                    <div class="voice-bar" style="animation-delay: 0.2s"></div>
                    <div class="voice-bar" style="animation-delay: 0.3s"></div>
                </div>

                <div class="relative flex items-end gap-2 bg-slate-100 dark:bg-slate-800 rounded-2xl p-2 shadow-inner">
                    <input type="file" id="file-input" accept="image/*" class="hidden" onchange="handleFileSelect(event)">
                    <button onclick="document.getElementById('file-input').click()" class="p-3 text-slate-400 hover:text-blue-500"><i class="fa-solid fa-paperclip text-xl"></i></button>

                    <textarea id="user-input" rows="1" placeholder="Talk to me..." class="w-full bg-transparent border-0 focus:ring-0 py-3 px-2 resize-none max-h-48" onkeydown="handleKeyDown(event)"></textarea>
                    
                    <button id="mic-btn" onclick="toggleManualMic()" class="p-3 text-slate-400 transition-all">
                        <i class="fa-solid fa-microphone text-xl"></i>
                    </button>
                    
                    <button id="send-btn" onclick="sendMessage()" class="p-3 bg-blue-600 text-white rounded-xl hover:bg-blue-700 disabled:opacity-50">
                        <i class="fa-solid fa-paper-plane" id="send-icon"></i>
                    </button>
                </div>
            </div>
        </main>
    </div>

    <div id="settings-modal" class="hidden fixed inset-0 z-50 bg-black/60 flex items-center justify-center p-4 backdrop-blur-sm">
        <div class="bg-white dark:bg-slate-900 p-8 rounded-3xl w-full max-w-md shadow-2xl">
            <h2 class="text-2xl font-bold mb-6">Configuration</h2>
            <div class="space-y-4">
                <div>
                    <label class="text-xs font-bold text-slate-400 uppercase">OpenRouter API Key</label>
                    <input type="password" id="api-key-input" class="w-full p-3 rounded-xl border dark:bg-slate-800 dark:border-slate-700 mt-1">
                </div>
                <div>
                    <label class="text-xs font-bold text-slate-400 uppercase">AI Model (Vision Support Reqd)</label>
                    <input type="text" id="model-input" value="google/gemini-2.0-flash-exp:free" class="w-full p-3 rounded-xl border dark:bg-slate-800 dark:border-slate-700 mt-1">
                </div>
            </div>
            <button onclick="saveSettings()" class="w-full mt-8 bg-blue-600 text-white py-4 rounded-xl font-bold">Apply Settings</button>
        </div>
    </div>

    <script>
        let STATE = {
            chats: [],
            currentId: null,
            settings: { apiKey: '', model: 'google/gemini-2.0-flash-exp:free' },
            isThinking: false,
            isHandsFree: false,
            isRecording: false,
            attachedImage: null
        };

        let recognition;

        window.onload = () => {
            const saved = localStorage.getItem('ai_vision_voice_v7');
            if (saved) STATE = { ...STATE, ...JSON.parse(saved) };
            if (STATE.chats.length === 0) createNewChat();
            
            document.getElementById('api-key-input').value = STATE.settings.apiKey;
            document.getElementById('model-input').value = STATE.settings.model;
            document.getElementById('hands-free-toggle').checked = STATE.isHandsFree;
            
            initVoiceRecognition();
            updateUI();
        };

        // --- Voice Logic (Hindi + English) ---
        function initVoiceRecognition() {
            const Speech = window.SpeechRecognition || window.webkitSpeechRecognition;
            if (!Speech) return;
            recognition = new Speech();
            recognition.continuous = true;
            recognition.interimResults = false;
            // Set to a broad range or toggle based on context
            recognition.lang = 'en-US'; 

            recognition.onstart = () => { 
                STATE.isRecording = true;
                updateMicUI(true);
            };

            recognition.onend = () => {
                STATE.isRecording = false;
                updateMicUI(false);
                // Auto-restart if hands-free is on and AI isn't speaking
                if (STATE.isHandsFree && !window.speechSynthesis.speaking && !STATE.isThinking) {
                    try { recognition.start(); } catch(e) {}
                }
            };

            recognition.onresult = (e) => {
                const transcript = e.results[e.results.length - 1][0].transcript;
                document.getElementById('user-input').value = transcript;
                sendMessage();
            };
        }

        function toggleManualMic() {
            if (STATE.isRecording) recognition.stop();
            else recognition.start();
        }

        function toggleHandsFree() {
            STATE.isHandsFree = document.getElementById('hands-free-toggle').checked;
            if (STATE.isHandsFree) recognition.start();
            else recognition.stop();
            saveData();
        }

        function updateMicUI(active) {
            const micBtn = document.getElementById('mic-btn');
            const status = document.getElementById('status-tag');
            const indicator = document.getElementById('voice-indicator');
            
            if (active) {
                micBtn.classList.add('active-mic');
                status.innerText = "Listening...";
                status.className = "text-[10px] uppercase font-black bg-red-100 dark:bg-red-900/30 px-3 py-1 rounded-full text-red-600";
                indicator.classList.remove('hidden');
            } else {
                micBtn.classList.remove('active-mic');
                status.innerText = "Standby";
                status.className = "text-[10px] uppercase font-black bg-slate-100 dark:bg-slate-800 px-3 py-1 rounded-full text-slate-500";
                indicator.classList.add('hidden');
            }
        }

        // --- Hindi/English Speech Synthesis ---
        function speakResponse(text) {
            window.speechSynthesis.cancel();
            if (STATE.isHandsFree && recognition) recognition.stop(); // Stop listening while talking

            const utterance = new SpeechSynthesisUtterance(text.replace(/[#*`]/g, ''));
            
            // Detect Hindi characters
            const isHindi = /[\u0900-\u097F]/.test(text);
            const voices = window.speechSynthesis.getVoices();
            
            if (isHindi) {
                utterance.lang = 'hi-IN';
                // Try to find a specific Hindi voice if available
                const hindiVoice = voices.find(v => v.lang.includes('hi-IN'));
                if (hindiVoice) utterance.voice = hindiVoice;
            } else {
                utterance.lang = 'en-US';
            }

            utterance.onstart = () => document.getElementById('stop-voice-btn').classList.remove('hidden');
            utterance.onend = () => {
                document.getElementById('stop-voice-btn').classList.add('hidden');
                // Restart listening after talking if in hands-free mode
                if (STATE.isHandsFree) setTimeout(() => recognition.start(), 500);
            };

            window.speechSynthesis.speak(utterance);
        }

        // --- Core Messaging ---
        async function sendMessage() {
            const input = document.getElementById('user-input');
            const text = input.value.trim();
            if (!text && !STATE.attachedImage || STATE.isThinking) return;
            if (!STATE.settings.apiKey) { alert("Add API Key!"); return; }

            STATE.isThinking = true;
            toggleLoading(true);
            const chat = STATE.chats.find(c => c.id === STATE.currentId);
            
            let content;
            if (STATE.attachedImage) {
                content = [{ type: "text", text: text || "Check this image" }, { type: "image_url", image_url: { url: STATE.attachedImage } }];
            } else {
                content = text;
            }

            chat.messages.push({ role: 'user', content });
            input.value = ''; clearImage(); renderChat();

            try {
                const response = await fetch("https://openrouter.ai/api/v1/chat/completions", {
                    method: "POST",
                    headers: { "Authorization": `Bearer ${STATE.settings.apiKey}`, "Content-Type": "application/json" },
                    body: JSON.stringify({ model: STATE.settings.model, messages: chat.messages })
                });
                const data = await response.json();
                const aiMsg = data.choices[0].message;
                chat.messages.push(aiMsg);
                renderChat();
                speakResponse(aiMsg.content);
            } catch (err) {
                console.error(err);
            } finally {
                STATE.isThinking = false;
                toggleLoading(false);
                saveData();
            }
        }

        // --- Helpers ---
        function stopSpeaking() { window.speechSynthesis.cancel(); }
        function handleFileSelect(e) {
            const file = e.target.files[0];
            const reader = new FileReader();
            reader.onload = (ev) => {
                STATE.attachedImage = ev.target.result;
                document.getElementById('preview-img').src = STATE.attachedImage;
                document.getElementById('img-preview-box').classList.remove('hidden');
            };
            reader.readAsDataURL(file);
        }
        function clearImage() { STATE.attachedImage = null; document.getElementById('img-preview-box').classList.add('hidden'); }
        function renderChat() {
            const container = document.getElementById('chat-container');
            const chat = STATE.chats.find(c => c.id === STATE.currentId);
            container.innerHTML = chat.messages.map(msg => {
                const isUser = msg.role === 'user';
                let html = '';
                if (Array.isArray(msg.content)) {
                    msg.content.forEach(p => {
                        if (p.type === 'text') html += marked.parse(p.text);
                        if (p.type === 'image_url') html += `<img src="${p.image_url.url}" class="max-w-xs rounded-lg my-2 shadow">`;
                    });
                } else { html = marked.parse(msg.content); }
                return `<div class="flex ${isUser ? 'justify-end' : 'justify-start'}"><div class="max-w-[85%] p-4 rounded-2xl ${isUser ? 'bg-blue-600 text-white rounded-tr-none' : 'bg-slate-100 dark:bg-slate-800 prose dark:prose-invert'}">${html}</div></div>`;
            }).join('');
            container.scrollTop = container.scrollHeight;
        }
        function createNewChat() { const id = Date.now().toString(); STATE.chats.unshift({ id, title: 'Chat ' + STATE.chats.length, messages: [] }); STATE.currentId = id; updateUI(); }
        function switchChat(id) { STATE.currentId = id; updateUI(); }
        function saveData() { localStorage.setItem('ai_vision_voice_v7', JSON.stringify(STATE)); }
        function updateUI() { renderSidebar(); renderChat(); }
        function renderSidebar() {
            document.getElementById('chat-list').innerHTML = STATE.chats.map(c => `<div onclick="switchChat('${c.id}')" class="p-3 rounded-lg cursor-pointer ${c.id === STATE.currentId ? 'bg-blue-50 dark:bg-blue-900/20 text-blue-600 font-bold' : ''}">${c.title}</div>`).join('');
        }
        function toggleSettings() { document.getElementById('settings-modal').classList.toggle('hidden'); }
        function saveSettings() { STATE.settings.apiKey = document.getElementById('api-key-input').value; STATE.settings.model = document.getElementById('model-input').value; toggleSettings(); saveData(); }
        function toggleLoading(s) { document.getElementById('send-icon').className = s ? "fa-solid fa-spinner animate-spin" : "fa-solid fa-paper-plane"; }
        function handleKeyDown(e) { if (e.key === 'Enter' && !e.shiftKey) { e.preventDefault(); sendMessage(); } }
        function toggleSidebar() { document.getElementById('sidebar').classList.toggle('-translate-x-full'); }
    </script>
</body>
</html>
